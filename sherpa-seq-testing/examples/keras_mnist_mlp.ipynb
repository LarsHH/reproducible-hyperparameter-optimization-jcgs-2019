{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SHERPA is a Python library for hyperparameter tuning of machine learning models.\n",
    "Copyright (C) 2018  Lars Hertel, Peter Sadowski, and Julian Collado.\n",
    "\n",
    "This file is part of SHERPA.\n",
    "\n",
    "SHERPA is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "SHERPA is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with SHERPA.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "import sherpa\n",
    "import sherpa.algorithms.bayesian_optimization as bayesian_optimization\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sherpa Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [sherpa.Continuous('learning_rate', [1e-4, 1e-2]),\n",
    "              sherpa.Discrete('num_units', [32, 128]),\n",
    "              sherpa.Choice('activation', ['relu', 'tanh', 'sigmoid'])]\n",
    "algorithm = bayesian_optimization.GPyOpt(max_num_trials=50)\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=algorithm,\n",
    "                     lower_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "for trial in study:\n",
    "    lr = trial.parameters['learning_rate']\n",
    "    num_units = trial.parameters['num_units']\n",
    "    act = trial.parameters['activation']\n",
    "\n",
    "    # Create model\n",
    "    model = Sequential([Flatten(input_shape=(28, 28)),\n",
    "                        Dense(num_units, activation=act),\n",
    "                        Dense(10, activation='softmax')])\n",
    "    optimizer = Adam(lr=lr)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    for i in range(epochs):\n",
    "        model.fit(x_train, y_train)\n",
    "        loss, accuracy = model.evaluate(x_test, y_test)\n",
    "        study.add_observation(trial=trial, iteration=i,\n",
    "                              objective=accuracy,\n",
    "                              context={'loss': loss})\n",
    "        if study.should_trial_stop(trial):\n",
    "            break \n",
    "    study.finalize(trial=trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
