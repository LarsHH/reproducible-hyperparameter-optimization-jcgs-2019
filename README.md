# Code for Reproducible Hyperparameter Optimization

## To reproduce results in paper
All results in the paper can be reproduced using the `evaluation.ipynb` Jupyter Notebook. The code can be viewed under https://github.com/LarsHH/reproducible-hyperparameter-optimization-jcgs-2019/blob/submission/evaluation.ipynb . The evaluation code is written in R and a Cran R installation is required (https://cran.r-project.org/). To open and run the Jupyter notebook Python and Jupyter are required (https://jupyter.org/install). To run R in a Jupyter notebook the R Kernel for Jupyter can be used (https://github.com/IRkernel/IRkernel). Further R packages are required upon running the code, however those can be installed from within the notebook.

# To re-run hyperparameter optimization:
The individual experiment folders contain the results for all hyperparameter optimizations that the results are based on. If however there is a need to re-run the hyperparameter optimizations themselves, this can be done by running the runner.py file with Python in each experiment folder. The hyperparameter optimization requires Sherpa (pip install parameter-sherpa) and Keras/Tensorflow and Scikit-Learn. Note that the output of the hyperparameter optimizations was reduced to the necessary information so that CSVs with the results are small enough to be provided here. The code to generate the reduced CSVs can be found in `merge-datasets.ipynb`.
